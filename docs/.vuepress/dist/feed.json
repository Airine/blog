{
    "version": "https://jsonfeed.org/version/1",
    "title": "",
    "home_page_url": "https://www.banli17.com",
    "feed_url": "https://www.banli17.com/feed.json",
    "items": [
        {
            "id": "https://www.banli17.com/browser/",
            "url": "https://www.banli17.com/browser/",
            "title": "浏览器原理",
            "summary": "浏览器原理\n多进程架构\n\n为什么打开一个页面，有 4 个进程？\n\n进程和线程\n线程是用来执行任务的，它不能独立存在，必须由进程来启动和管理。\n进程是程序的运行实例，程序启动时，操作系统给程序分配的一块内存，用来存放代码、运行中的数据和一个执行任务的主线程。这样一个运行环境叫做进程。\n进程使用多线程来提高运算效率。\n特点：\n\n进程中一个线程出错，会导致整个进程崩溃。\n线程之间共享进程的数据。\n当一个进程关闭后，操作系统会回收进程所占用的内存。\n进程之间是相互隔离的，一个挂了不影响另一个。之间数据通信需要使用 IPC 的机制。\n\n单进程\n\n不稳定，一个线程出错，就导致进程崩溃。\n不流畅，如果只有一个线程，死循环时，其它的任务都要等待。\n不安全，插件或页面代码能使用主进程数据，对系统进行操作,，直接控制电脑。因为主进程不可能隔离，这样浏览器就不能读写系统了。另外，其它页面的内容，如果是在写邮件，也没了。\n\n多进程\n\n解决不稳定，因为进程是隔离的，互不影响\n解决不流畅，即使 js 阻塞，也不影响浏览器和其它页面，死循环只影响当前 tab\n解决不安全，使用安全沙箱，给渲染进程和插件进程上锁。无法获取系统权限。\n\n架构\n\n渲染进程: 负责 html css js 转成网页，排版引擎 blink 和 js 引擎 v8 都在这，默认情况下，每个 tab 会创建一个渲染进程。同一个站点如,x.y.com z.y.com 新页面会复用同一个进程，因为有时需要共享 js 执行环境。iframe 也会新开进程。\n插件进程\n网络进程\n浏览器主进程： 负责界面显示，用户交互，子进程管理，存储\nGPU 进程：初衷是实现 css 3d，后来用来绘制 UI 界面\nv8 代理解析工具 chrome 支持 js 写连接代理的脚本，叫在线 pac 代理脚本，这个进程叫 Utility: V8 Proxy Resolver。\nAudio 服务进程，对所有页面提供基础服务。\n\n缺点：\n\n更高的资源占用\n更复杂的体系架构：耦合高、扩展性差\n\n未来的架构\n\n面向服务的架构，将原来的模块重构成服务，每个服务定义好接口，通过 IPc 来通信，从而内聚，松耦合，易于维护和扩展\n\n此外，chrome 还提供了灵活的弹性架构，在资源受限制的设备上，会将很多服务整合到一个进程，节省内存\n",
            "image": "https://www.banli17.com/1.png",
            "date_modified": "2019-10-04T03:34:05.921Z"
        },
        {
            "id": "https://www.banli17.com/browser/gc.html",
            "url": "https://www.banli17.com/browser/gc.html",
            "title": "垃圾回收机制",
            "summary": "垃圾回收机制",
            "date_modified": "2019-10-04T03:34:05.922Z"
        },
        {
            "id": "https://www.banli17.com/browser/v8.html",
            "url": "https://www.banli17.com/browser/v8.html",
            "title": "v8 工作原理",
            "summary": "v8 工作原理\n垃圾回收\n栈中的垃圾回收\n执行栈中有一个记录当前执行状态的指针（ESP)，指向栈顶的函数执行上下文，函数执行完成后，ESP 会下移，函数执行上下文就是无效内存了，如果调用新函数，这块内存会被覆盖掉，用来存放新函数的执行上下文。\n所以说，当一个函数执行完后，JS 引擎会通过向下移动 ESP 来销毁该函数保存在栈中的执行上下文。\n堆中的垃圾回收\n堆中的垃圾回收，就用到了 JS 的垃圾回收器。\n代际假说有两个特点：\n\n大部分对象在内存中存在的时间很短。\n不死的对象，会存活的更久。\n\nV8 将堆分为新生代和老生代两个区域，新生代存放生存时间短的对象，老生代存放生存时间长的对象。\n新生区通常只支持 1-8M 容量，老生区支持的容量大。V8 分别堆这两个区使用了不同的垃圾回收器。\n\n副垃圾回收器，负责新生代的垃圾回收。\n主垃圾回收器，负责老生代的垃圾回收。\n\n垃圾回收器工作流程\n垃圾回收器的工作流程是一致的：\n\n标记空间中活动对象和非活动对象。\n回收非活动对象所占用的内存。即清理标记为非活动对象的内存。\n内存整理，通常垃圾回收后，内存会变得不连续，有内存碎片。\n\n副垃圾回收器\n副垃圾回收器主要负责新生区的垃圾回收，通常小的对象分配到这里。\n新生代中用 Scavenge 算法来处理，即把新生区对半分为两个区域，一般是对象区域，一半是空闲区域。新加入的对象会存放在对象区域，当对象区域快满时，就需要一次垃圾回收。\n垃圾回收过程中，首先标记对象区域中的垃圾，标记完成后，进行垃圾清理阶段，副垃圾回收器会把存活的对象复制到空闲区域，同时将它们有序的排列起来，所以这个复制过程相当于是内存整理。\n复制完成后，对象区域和空闲区域进行反转，这种角色反转的操作能让新生代的两块内存可以无限重复使用下去。\n因为 Scavenge 算法，每次要复制存活对象到空闲区域，复制需要时间成本，所以如果新生区空间太大，每次清理需要很长时间，为了执行效率，新生区会设置的比较小。\n但是由于新生区空间不大，会很快被装满，所以 JS 引擎采用对象晋升策略，即经过两次垃圾回收还存活的对象，会被移动到老生区中。\n主垃圾回收器\n主垃圾回收器负责老生区的垃圾回收，除了新生区晋升的对象，一些大的对象也会直接分配到老生区，所以老生区中的对象有两个特点：占用空间大、存活时间长。\n如果使用 Scavenge 算法，复制大对象会花很长时间，同时还会浪费一半的空间。所以主垃圾回收器采用的是标记-清除(Mark-Sweep)算法。\n\n标记过程，从根元素开始，进行递归遍历，能到达的元素就标记为活动对象，没有到达的就是垃圾数据。\n垃圾清除\n\n但是上面的标记-清除算法，如果多次执行后，会有大量的内存碎片，会导致大对象无法分配到足够的连续内存。所以有产生了一个新的算法标记-整理(Mark-Compact)，是直接将活动对象从开始进行排列，然后将边界后面的内存一次清空。\n全停顿\nJS 是运行在主线程上的，一旦执行垃圾回收算法，JS 脚本会停止执行，等待垃圾回收完毕后再恢复执行，这种行为叫做全停顿(Stop-The-World)。\n如果堆中数据 1.5G，V8 清理垃圾的时间会超过 1s。这样会让应用的性能和响应能力下降。新生代小，影响不大，但是老生代就不能这样了，所以为了降低卡顿，V8 将标记过程分为一个个子标记过程，同时让垃圾回收标记和 JS 应用逻辑交替执行，直到标记阶段完成，这个算法叫增量标记算法(Incremental Marking)。\n新生代和老生代的标记过程是同一过程，之后新生代把存活的数据移动到空闲区，老生代把死去的对象加到空闲列表中。\nV8 还维护了一个空闲列表，也就是没有被使用的空闲空间列表，垃圾清理过程就是把没有标记的添加到空闲列表中！\n增量标记会受到中间穿插的 js 应用逻辑影响么？会造成标记结果不全或者错误么？\n不全没关系，新产生的垃圾下次再回收，分配内存使用空闲列表里面的。\n怎么看内存泄露\n\n一般是感官上的长时间运行页面卡顿，猜可能会有内存泄漏。\n使用 chrome 的 Performance 面板，观察内存变化 如何多次垃圾回收后，整体趋势是向上，就存在内部泄漏的可能！\n确定不使用的临时变量置为 null，当前 es6 普及场景下少使用闭包也是一种方法。\n\n可能导致内存泄露\n\n全局变量过大\n定时器没有清除\n闭包\nDOM 引用\n",
            "date_modified": "2019-10-04T03:34:05.924Z"
        },
        {
            "id": "https://www.banli17.com/",
            "url": "https://www.banli17.com/",
            "title": "Home",
            "date_modified": "2019-10-04T03:34:05.924Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/1.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/1.html",
            "title": "透视 http 协议",
            "summary": "透视 http 协议\n开篇词｜ To Be a HTTP Hero\n你好，我是罗剑锋（Chrono（加微信：642945106 发送“赠送”领取赠送精品课程 发数字“2”获取众筹列表。）），一名埋头于前线，辛勤“耕耘”了十余载的资深“码农”。\n工作的这十多年来，我开发过智能 IC 卡，也倒腾过商用密码机；做过政务项目，也做过商务搜索；写过网游核心引擎，也写过 CDN 存储系统；在 Windows 上用 C/C++ 做客户端，在 AIX、Linux 上用 Java、PHP 写后台服务……现在则是专注于“魔改”Nginx，深度定制实现网络协议的分析与检测。\n当极客时间的编辑联系我，要我写 HTTP 专栏的时候，我的第一反应是：“HTTP 协议好简单的，有这个必要吗？”\n你可能也会有同样的想法：“HTTP 不就是请求 / 响应、GET/POST、Header/Body 吗？网络上的资料一抓一大把，有什么问题搜一下就是了。”\n不瞒你说，我当时就是这么想的，在之前的工作中也是一直这么做的，而且一直“感觉良好”，觉得 HTTP 就是这个样子，没有什么特别的地方，没有什么值得讲的。\n但在编辑的一再坚持下，我“勉为其难”接下了这个任务。然后做了一个小范围的“调查”，问一些周围的同事，各个领域的都有，比如产品、开发、运维、测试、前端、后端、手机端……想看看他们有什么意见。\n出乎我的意料，他们无一例外都对这个“HTTP 专栏”有很强烈的需求，想好好“补补课”，系统地学习了解 HTTP，这其中甚至还包括有七、八年（甚至更多）工作经验的老手。\n这不禁让我陷入了思考，为什么如此“简单”的协议却还有这么多的人想要学呢？\n我想，一个原因可能是 HTTP 协议“太常见”了。就像现实中的水和空气一样，如此重要却又如此普遍，普遍到我们几乎忽视了它的存在。真的很像那句俗语所说：“鱼总是最后看见水的”，但水对鱼的生存却又是至关重要。\n我认真回忆了一下这些年的工作经历，这才发现 HTTP 只是表面上显得简单，而底层的运行机制、工作原理绝不简单，可以说是非常地复杂。只是我们平常总是“KPI 优先”，网上抓到一个解决方法用过就完事了，没有去深究里面的要点和细节。\n下面的几个场景，都是我周围同事的实际感受，你是否也在工作中遇到过这样的困惑呢？你能把它们都解释清楚吗？\n用 Nginx 搭建 Web 服务器，照着网上的文章配好了，但里面那么多的指令，什么 keepalive、rewrite、proxy_pass 都是怎么回事？为什么要这么配置？\n用 Python 写爬虫，URI、URL“傻傻分不清”，有时里面还会加一些奇怪的字符，怎么处理才好？\n都说 HTTP 缓存很有用，可以大幅度提升系统性能，可它是怎么做到的？又应该用在何时何地？\nHTTP 和 HTTPS 是什么关系？还经常听说有 SSL/TLS/SNI/OCSP/ALPN……这么多稀奇古怪的缩写，头都大了，实在是搞不懂。\n其实这些问题也并不是什么新问题，把关键字粘贴进搜索栏，再点一下按钮，搜索引擎马上就能找出几十万个相关的页面。但看完第一页的前几个链接后，通常还是有种“懵懵懂懂”“似懂非懂”的感觉，觉得说的对，又不全对，和自己的思路总是不够“Match”。\n不过大多数情况下你可能都没有时间细想，优先目标是把手头的工作“对付过去”。长此以来，你对 HTTP 的认识也可能仅限于这样的“知其然，而不知其所以然”，实际情况就是 HTTP 天天用，时时用，但想认真、系统地学习一下，梳理出自己的知识体系，经常会发现无从下手。\n我把这种 HTTP 学习的现状归纳为三点：正式资料“少”、网上资料“杂”、权威资料“难”。\n第一个，正式资料“少”。\n上购书网站，搜个 Python、Java，搜个 MySQL、Node.js，能出一大堆。但搜 HTTP，实在是少得可怜，那么几本，一只手的手指头就可以数得过来，和语言类、数据库类、框架类图书真是形成了鲜明的对比。\n现有的 HTTP 相关图书我都看过，怎么说呢，它们都有一个特点，“广撒网，捕小鱼”，都是知识点，可未免太“照本宣科”了，理论有余实践不足，看完了还是不知道怎么去用。\n而且这些书的“岁数”都很大，依据的都是 20 年前的 RFC2616，很多内容都不合时宜，而新标准 7230 已经更新了很多关键的细节。\n第二个，网上资料“杂”。\n正式的图书少，而且过时，那就求助于网络社区吧。现在的博客、论坛、搜索引擎非常发达，网上有很多 HTTP 协议相关的文章，也都是网友的实践经验分享，“干货”很多，很能解决实际问题。\n但网上文章的特点是细小、零碎，通常只“钉”在一个很小的知识点上，而且由于帖子长度的限制，无法深入展开论述，很多都是“浅尝辄止”，通常都止步在“How”层次，很少能说到“Why”，能说透的更是寥寥无几。\n网文还有一个难以避免的“毛病”，就是“良莠不齐”。同一个主题可能会有好几种不同的说法，有的还会互相矛盾、以讹传讹。这种情况是最麻烦的，你必须花大力气去鉴别真假，不小心就会被“带到沟里”。\n可想而知，这种“东一榔头西一棒子”的学习方式，用“碎片”拼凑出来的 HTTP 知识体系是非常不完善的，会有各种漏洞，遇到问题时基本派不上用场，还得再去找其他的“碎片”。\n第三个，权威资料“难”。\n图书少，网文杂，我们还有一个终极的学习资料，那就是 RFC 文档。\nRFC 是互联网工程组（IETF）发布的官方文件，是对 HTTP 最权威的定义和解释。但它也是最难懂的，全英文看着费劲，理解起来更是难上加难，文档之间还会互相关联引用，“劝退率”极高。\n这三个问题就像是“三座大山”，阻碍了像你这样的很多有心人去学习、了解 HTTP 协议。\n那么，怎么才能更好地学习 HTTP 呢？\n我为这个专栏定了一个基调：“要有广度，但更要有深度”。目标是成为含金量最高的 HTTP 学习资料，新手可以由浅入深、系统学习，老手可以温故知新、查缺补漏，让你花最少的时间，用最少的精力，掌握最多、最全面、最系统的知识。\n由于 HTTP 应用得非常广泛，几乎涉及到所有的领域，所以我会在广度上从 HTTP 尽量向外扩展，不只讲协议本身，与它相关的 TCP/IP、DNS、SSL/TLS、Web Server 等都会讲到，而且会把它们打通串联在一起，形成知识链，让你知道它们之间是怎么联系、怎么运行的。\n专栏文章的深度上我也是下足了功夫，全部基于最新的 RFC 标准文档，再结合我自己多年的实践体会，力求讲清讲透，能让你看了以后有豁然开朗的感觉。\n比如分析 HTTPS，我会用 Wireshark 从建立 TCP 连接时就开始抓包，从二进制最底层来分析里面的 Record、Cipher Suite、Extension，讲 ECDHE、AES、SHA384，再画出详细的流程图，做到“一览无余”。\n陆游有诗：“纸上得来终觉浅，绝知此事要躬行”。学习网络协议最重要的就是实践，在专栏里我还会教你用 Nginx 搭建一个“麻雀虽小，五脏俱全”的实验环境，让你与 HTTP 零距离接触。\n它有一个最大的优点：自身就是一个完整的网络环境，即使不联网也能够在里面收发 HTTP 消息。\n我还精心设计了配套的测试用例，最小化应用场景，排除干扰因素，你可以在里面任意测试 HTTP 的各种特性，再配合 Wireshark 抓包，就能够理论结合实践，更好地掌握 HTTP 的知识。\n每一讲的末尾，我也会留几个思考题，你可以把它当作是求职时的面试官问题，尽量认真思考后再回答，这样能够把专栏的学习由“被动地听”，转变为“主动地学”，实现“学以致用”。\n当然了，你和我的“兴趣点”不可能完全一样，我在讲课时也难免“顾此失彼”“挂一漏万”，希望你积极留言，我会视情况做些调整，或者用答疑的形式补充没讲到的内容。\n今年是万维网和 HTTP 诞生 30 周年，也是 HTTP/1.1 诞生 20 周年，套用莎翁《哈姆雷特》里的名句，让我们在接下来的三个月里一起努力。\n“To Be a HTTP Hero！”",
            "date_modified": "2019-10-04T03:34:05.926Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-3.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-3.html",
            "title": "03 | HTTP 世界全览（上）：与 HTTP 相关的各种概念",
            "summary": "03 | HTTP 世界全览（上）：与 HTTP 相关的各种概念\n在上一讲的末尾，我画了一张图，里面是与 HTTP 关联的各种技术和知识点，也可以说是这个专栏的总索引，不知道你有没有认真看过呢？\n那张图左边的部分是与 HTTP 有关系的各种协议，比较偏向于理论；而右边的部分是与 HTTP 有关系的各种应用技术，偏向于实际应用。\n我希望借助这张图帮你澄清与 HTTP 相关的各种概念和角色，让你在实际工作中清楚它们在链路中的位置和作用，知道发起一个 HTTP 请求会有哪些角色参与，会如何影响请求的处理，做到“手中有粮，心中不慌”。\n因为那张图比较大，所以我会把左右两部分拆开来分别讲，今天先讲右边的部分，也就是与 HTTP 相关的各种应用，着重介绍互联网、浏览器、Web 服务器等常见且重要的概念。\n\n为了方便你查看，我又把这部分重新画了一下，比那张大图小了一些，更容易地阅读，你可以点击查看。\n暖场词就到这里，让我们正式开始吧。\n网络世界\n你一定已经习惯了现在的网络生活，甚至可能会下意识地认为网络世界就应该是这个样子的：“一张平坦而且一望无际的巨大网络，每一台电脑就是网络上的一个节点，均匀地点缀在这张网上”。\n这样的理解既对，又不对。从抽象的、虚拟的层面来看，网络世界确实是这样的，我们可以从一个节点毫无障碍地访问到另一个节点。\n但现实世界的网络却远比这个抽象的模型要复杂得多。实际的互联网是由许许多多个规模略小的网络连接而成的，这些“小网络”可能是只有几百台电脑的局域网，可能是有几万、几十万台电脑的广域网，可能是用电缆、光纤构成的固定网络，也可能是用基站、热点构成的移动网络……\n互联网世界更像是由数不清的大小岛屿组成的“千岛之国”。\n互联网的正式名称是 Internet，里面存储着无穷无尽的信息资源，我们通常所说的“上网”实际上访问的只是互联网的一个子集“万维网”（World Wide Web），它基于 HTTP 协议，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。\n互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。\n不过由于 HTTP 协议非常灵活、易于扩展，而且“超文本”的表述能力很强，所以很多其他原本不属于 HTTP 的资源也可以“包装”成 HTTP 来访问，这就是我们为什么能够总看到各种“网页应用”——例如“微信网页版”“邮箱网页版”——的原因。\n综合起来看，现在的互联网 90% 以上的部分都被万维网，也就是 HTTP 所覆盖，所以把互联网约等于万维网或 HTTP 应该也不算大错。\n浏览器\n上网就要用到浏览器，常见的浏览器有 Google 的 Chrome、Mozilla 的 Firefox、Apple 的 Safari、Microsoft 的 IE 和 Edge，还有小众的 Opera 以及国内的各种“换壳”的“极速”“安全”浏览器。\n那么你想过没有，所谓的“浏览器”到底是个什么东西呢？\n浏览器的正式名字叫“Web Browser”，顾名思义，就是检索、查看互联网上网页资源的应用程序，名字里的 Web，实际上指的就是“World Wide Web”，也就是万维网。\n浏览器本质上是一个 HTTP 协议中的请求方，使用 HTTP 协议获取网络上的各种资源。当然，为了让我们更好地检索查看网页，它还集成了很多额外的功能。\n例如，HTML 排版引擎用来展示页面，JavaScript 引擎用来实现动态化效果，甚至还有开发者工具用来调试网页，以及五花八门的各种插件和扩展。\n在 HTTP 协议里，浏览器的角色被称为“User Agent”即“用户代理”，意思是作为访问者的“代理”来发起 HTTP 请求。不过在不引起混淆的情况下，我们通常都简单地称之为“客户端”。\nWeb 服务器\n刚才说的浏览器是 HTTP 里的请求方，那么在协议另一端的应答方（响应方）又是什么呢？\n这个你一定也很熟悉，答案就是服务器，Web Server。\nWeb 服务器是一个很大也很重要的概念，它是 HTTP 协议里响应请求的主体，通常也把控着绝大多数的网络资源，在网络世界里处于强势地位。\n当我们谈到“Web 服务器”时有两个层面的含义：硬件和软件。\n硬件含义就是物理形式或“云”形式的机器，在大多数情况下它可能不是一台服务器，而是利用反向代理、负载均衡等技术组成的庞大集群。但从外界看来，它仍然表现为一台机器，但这个形象是“虚拟的”。\n软件含义的 Web 服务器可能我们更为关心，它就是提供 Web 服务的应用程序，通常会运行在硬件含义的服务器上。它利用强大的硬件能力响应海量的客户端 HTTP 请求，处理磁盘上的网页、图片等静态文件，或者把请求转发给后面的 Tomcat、Node.js 等业务应用，返回动态的信息。\n比起层出不穷的各种 Web 浏览器，Web 服务器就要少很多了，一只手的手指头就可以数得过来。\nApache 是老牌的服务器，到今天已经快 25 年了，功能相当完善，相关的资料很多，学习门槛低，是许多创业者建站的入门产品。\nNginx 是 Web 服务器里的后起之秀，特点是高性能、高稳定，且易于扩展。自 2004 年推出后就不断蚕食 Apache 的市场份额，在高流量的网站里更是不二之选。\n此外，还有 Windows 上的 IIS、Java 的 Jetty/Tomcat 等，因为性能不是很高，所以在互联网上应用得较少。\nCDN\n浏览器和服务器是 HTTP 协议的两个端点，那么，在这两者之间还有别的什么东西吗？\n当然有了。浏览器通常不会直接连到服务器，中间会经过“重重关卡”，其中的一个重要角色就叫做 CDN。\nCDN，全称是“Content Delivery Network”，翻译过来就是“内容分发网络”。它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。\nCDN 有什么好处呢？\n简单来说，它可以缓存源站的数据，让浏览器的请求不用“千里迢迢”地到达源站服务器，直接在“半路”就可以获取响应。如果 CDN 的调度算法很优秀，更可以找到离用户最近的节点，大幅度缩短响应时间。\n打个比方，就好像唐僧西天取经，刚出长安城，就看到阿难与迦叶把佛祖的真经递过来了，是不是很省事？\nCDN 也是现在互联网中的一项重要基础设施，除了基本的网络加速外，还提供负载均衡、安全防护、边缘计算、跨运营商网络等功能，能够成倍地“放大”源站服务器的服务能力，很多云服务商都把 CDN 作为产品的一部分，我也会在后面用一讲的篇幅来专门讲解 CDN。\n爬虫\n前面说到过浏览器，它是一种用户代理，代替我们访问互联网。\n但 HTTP 协议并没有规定用户代理后面必须是“真正的人类”，它也完全可以是“机器人”，这些“机器人”的正式名称就叫做“爬虫”（Crawler），实际上是一种可以自动访问 Web 资源的应用程序。\n“爬虫”这个名字非常形象，它们就像是一只只不知疲倦的、辛勤的蚂蚁，在无边无际的网络上爬来爬去，不停地在网站间奔走，搜集抓取各种信息。\n据估计，互联网上至少有 50% 的流量都是由爬虫产生的，某些特定领域的比例还会更高，也就是说，如果你的网站今天的访问量是十万，那么里面至少有五六万是爬虫机器人，而不是真实的用户。\n爬虫是怎么来的呢？\n绝大多数是由各大搜索引擎“放”出来的，抓取网页存入庞大的数据库，再建立关键字索引，这样我们才能够在搜索引擎中快速地搜索到互联网角落里的页面。\n爬虫也有不好的一面，它会过度消耗网络资源，占用服务器和带宽，影响网站对真实数据的分析，甚至导致敏感信息泄漏。所以，又出现了“反爬虫”技术，通过各种手段来限制爬虫。其中一项就是“君子协定”robots.txt，约定哪些该爬，哪些不该爬。\n无论是“爬虫”还是“反爬虫”，用到的基本技术都是两个，一个是 HTTP，另一个就是 HTML。\nHTML/WebService/WAF\n到现在我已经说完了图中右边的五大部分，而左边的 HTML、WebService、WAF 等由于与 HTTP 技术上实质关联不太大，所以就简略地介绍一下，不再过多展开。\nHTML 是 HTTP 协议传输的主要内容之一，它描述了超文本页面，用各种“标签”定义文字、图片等资源和排版布局，最终由浏览器“渲染”出可视化页面。\nHTML 目前有两个主要的标准，HTML4 和 HTML5。广义上的 HTML 通常是指 HTML、JavaScript、CSS 等前端技术的组合，能够实现比传统静态页面更丰富的动态页面。\n接下来是 Web Service，它的名字与 Web Server 很像，但却是一个完全不同的东西。\nWeb Service 是一种由 W3C 定义的应用服务开发规范，使用 client-server 主从架构，通常使用 WSDL 定义服务接口，使用 HTTP 协议传输 XML 或 SOAP 消息，也就是说，它是一个基于 Web（HTTP）的服务架构技术，既可以运行在内网，也可以在适当保护后运行在外网。\n因为采用了 HTTP 协议传输数据，所以在 Web Service 架构里服务器和客户端可以采用不同的操作系统或编程语言开发。例如服务器端用 Linux+Java，客户端用 Windows+C#，具有跨平台跨语言的优点。\nWAF 是近几年比较“火”的一个词，意思是“网络应用防火墙”。与硬件“防火墙”类似，它是应用层面的“防火墙”，专门检测 HTTP 流量，是防护 Web 应用的安全技术。\nWAF 通常位于 Web 服务器之前，可以阻止如 SQL 注入、跨站脚本等攻击，目前应用较多的一个开源项目是 ModSecurity，它能够完全集成进 Apache 或 Nginx。\n小结\n今天我详细介绍了与 HTTP 有关系的各种应用技术，在这里简单小结一下要点。\n\n互联网上绝大部分资源都使用 HTTP 协议传输；\n浏览器是 HTTP 协议里的请求方，即 User Agent；\n服务器是 HTTP 协议里的应答方，常用的有 Apache 和 Nginx；\nCDN 位于浏览器和服务器之间，主要起到缓存加速的作用；\n爬虫是另一类 User Agent，是自动访问网络资源的程序。\n\n希望通过今天的讲解，你能够更好地理解这些概念，也利于后续的课程学习。\n课下作业\n\n你觉得 CDN 在对待浏览器和爬虫时会有差异吗？为什么？\n你怎么理解 WebService 与 Web Server 这两个非常相似的词？\n\n欢迎你通过留言分享答案，与我和其他同学一起讨论。如果你觉得有所收获，欢迎你把文章分享给你的朋友。\n\nrpc 就是把网络通信封装成了函数调用的形式，所以叫 rpc。soap 是 web service 的消息格式。RESTful 是一种 web 服务接口的设计理念。",
            "image": "https://www.banli17.com/imgs/2-3-1.png",
            "date_modified": "2019-10-04T03:34:05.929Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-2.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-2.html",
            "title": "02 | HTTP 是什么？HTTP 又不是什么？",
            "summary": "02 | HTTP 是什么？HTTP 又不是什么？\n首先我来问出这个问题：“你觉得 HTTP 是什么呢？”\n你可能会不假思索、脱口而出：“HTTP 就是超文本传输协议，也就是 HyperText Transfer Protocol。”\n回答非常正确！我必须由衷地恭喜你：能给出这个答案，就表明你具有至少 50%HTTP 相关的知识储备，应该算得上是“半个专家”了。\n不过让我们换个对话场景，假设不是我，而是由一位面试官问出刚才的问题呢？\n显然，这个答案有点过于简单了，不能让他满意，他肯定会再追问你一些问题：\n\n你是怎么理解 HTTP 字面上的“超文本”和“传输协议”的？\n能否谈一下你对 HTTP 的认识？越多越好。\nHTTP 有什么特点？有什么优点和缺点？\nHTTP 下层都有哪些协议？是如何工作的？\n\n几乎所有面试时问到的 HTTP 相关问题，都可以从这个最简单的“HTTP 是什么？”引出来。\n所以，今天的话题就从这里开始，深度地解答一下“HTTP 是什么？”，以及延伸出来的第二个问题“HTTP 不是什么？”\nHTTP 是什么\n咱们中国有个成语“人如其名”，意思是一个人的性格和特点是与他的名字相符的。\n先看一下 HTTP 的名字：“超文本传输协议”，它可以拆成三个部分，分别是：“超文本”“传输”和“协议”。我们从后往前来逐个解析，理解了这三个词，我们也就明白了什么是 HTTP。\n\n首先，HTTP 是一个协议。不过，协议又是什么呢？\n其实“协议”并不仅限于计算机世界，现实生活中也随处可见。例如，你在刚毕业时会签一个“三方协议”，找房子时会签一个“租房协议”，公司入职时还可能会签一个“保密协议”，工作中使用的各种软件也都带着各自的“许可协议”。\n刚才说的这几个都是“协议”，本质上与 HTTP 是相同的，那么“协议”有什么特点呢？\n第一点，协议必须要有两个或多个参与者，也就是“协”。\n如果只有你一个人，那你自然可以想干什么就干什么，想怎么玩就怎么玩，不会干涉其他人，其他人也不会干涉你，也就不需要所谓的“协议”。但是，一旦有了两个以上的参与者出现，为了保证最基本的顺畅交流，协议就自然而然地出现了。\n例如，为了保证你顺利就业，“三方协议”里的参与者有三个：你、公司和学校；为了保证你顺利入住，“租房协议”里的参与者有两个：你和房东。\n第二点，协议是对参与者的一种行为约定和规范，也就是“议”。\n协议意味着有多个参与者为了达成某个共同的目的而站在了一起，除了要无疑义地沟通交流之外，还必须明确地规定各方的“责、权、利”，约定该做什么不该做什么，先做什么后做什么，做错了怎么办，有没有补救措施等等。例如，“租房协议”里就约定了，租期多少个月，每月租金多少，押金是多少，水电费谁来付，违约应如何处理等等。\n好，到这里，你应该能够明白 HTTP 的第一层含义了。\nHTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。\n接下来我们看 HTTP 字面里的第二部分：“传输”。\n计算机和网络世界里有数不清的各种角色：CPU、内存、总线、磁盘、操作系统、浏览器、网关、服务器……这些角色之间相互通信也必然会有各式各样、五花八门的协议，用处也各不相同，例如广播协议、寻址协议、路由协议、隧道协议、选举协议等等。\nHTTP 是一个“传输协议”，所谓的“传输”（Transfer）其实很好理解，就是把一堆东西从 A 点搬到 B 点，或者从 B 点搬到 A 点，即“A&lt;===&gt;B”。\n别小看了这个简单的动作，它也至少包含了两项重要的信息。\n第一点，HTTP 协议是一个“双向协议”。\n也就是说，有两个最基本的参与者 A 和 B，从 A 开始到 B 结束，数据在 A 和 B 之间双向而不是单向流动。通常我们把先发起传输动作的 A 叫做请求方，把后接到传输的 B 叫做应答方或者响应方。拿我们最常见的上网冲浪来举例子，浏览器就是请求方 A，网易、新浪这些网站就是应答方 B。双方约定用 HTTP 协议来通信，于是浏览器把一些数据发送给网站，网站再把一些数据发回给浏览器，最后展现在屏幕上，你就可以看到各种有意思的新闻、视频了。\n第二点，数据虽然是在 A 和 B 之间传输，但并没有限制只有 A 和 B 这两个角色，允许中间有“中转”或者“接力”。\n这样，传输方式就从“A&lt;===&gt;B”，变成了“A&lt;=&gt;X&lt;=&gt;Y&lt;=&gt;Z&lt;=&gt;B”，A 到 B 的传输过程中可以存在任意多个“中间人”，而这些中间人也都遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意的额外功能，例如安全认证、数据压缩、编码转换等等，优化整个传输过程。\n说到这里，你差不多应该能够明白 HTTP 的第二层含义了。\nHTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。\n讲完了“协议”和“传输”，现在，我们终于到 HTTP 字面里的第三部分：“超文本”。\n既然 HTTP 是一个“传输协议”，那么它传输的“超文本”到底是什么呢？我还是用两点来进一步解释。\n所谓“文本”（Text），就表示 HTTP 传输的不是 TCP/UDP 这些底层协议里被切分的杂乱无章的二进制包（datagram），而是完整的、有意义的数据，可以被浏览器、服务器这样的上层应用程序处理。\n在互联网早期，“文本”只是简单的字符文字，但发展到现在，“文本”的涵义已经被大大地扩展了，图片、音频、视频、甚至是压缩包，在 HTTP 眼里都可以算做是“文本”。\n所谓“超文本”，就是“超越了普通文本的文本”，它是文字、图片、音频和视频等的混合体，最关键的是含有“超链接”，能够从一个“超文本”跳跃到另一个“超文本”，形成复杂的非线性、网状的结构关系。\n对于“超文本”，我们最熟悉的就应该是 HTML 了，它本身只是纯文字文件，但内部用很多标签定义了对图片、音频、视频等的链接，再经过浏览器的解释，呈现在我们面前的就是一个含有多种视听信息的页面。\nOK，经过了对 HTTP 里这三个名词的详细解释，下次当你再面对面试官时，就可以给出比“超文本传输协议”这七个字更准确更有技术含量的答案：“HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范”。\nHTTP 不是什么\n现在你对“HTTP 是什么？”应该有了比较清晰的认识，紧接着的问题就是“HTTP 不是什么？”，等价的问题是“HTTP 不能干什么？”。想想看，你能回答出来吗？\n因为 HTTP 是一个协议，是一种计算机间通信的规范，所以它不存在“单独的实体”。它不是浏览器、手机 APP 那样的应用程序，也不是 Windows、Linux 那样的操作系统，更不是 Apache、Nginx、Tomcat 那样的 Web 服务器。\n但 HTTP 又与应用程序、操作系统、Web 服务器密切相关，在它们之间的通信过程中存在，而且是一种“动态的存在”，是发生在网络连接、传输超文本数据时的一个“动态过程”。\nHTTP 不是互联网。\n互联网（Internet）是遍布于全球的许多网络互相连接而形成的一个巨大的国际网络，在它上面存放着各式各样的资源，也对应着各式各样的协议，例如超文本资源使用 HTTP，普通文件使用 FTP，电子邮件使用 SMTP 和 POP3 等。\n但毫无疑问，HTTP 是构建互联网的一块重要拼图，而且是占比最大的那一块。\nHTTP 不是编程语言。\n编程语言是人与计算机沟通交流所使用的语言，而 HTTP 是计算机与计算机沟通交流的语言，我们无法使用 HTTP 来编程，但可以反过来，用编程语言去实现 HTTP，告诉计算机如何用 HTTP 来与外界通信。\n很多流行的编程语言都支持编写 HTTP 相关的服务或应用，例如使用 Java 在 Tomcat 里编写 Web 服务，使用 PHP 在后端实现页面模板渲染，使用 JavaScript 在前端实现动态页面更新，你是否也会其中的一两种呢？\nHTTP 不是 HTML，这个可能要特别强调一下，千万不要把 HTTP 与 HTML 混为一谈，虽然这两者经常是同时出现。\nHTML 是超文本的载体，是一种标记语言，使用各种标签描述文字、图片、超链接等资源，并且可以嵌入 CSS、JavaScript 等技术实现复杂的动态效果。单论次数，在互联网上 HTTP 传输最多的可能就是 HTML，但要是论数据量，HTML 可能要往后排了，图片、音频、视频这些类型的资源显然更大。\nHTTP 不是一个孤立的协议。\n俗话说“一个好汉三个帮”，HTTP 也是如此。\n在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。\n小结\n\nHTTP 是一个用在计算机世界里的协议，它确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。\nHTTP 专门用来在两点之间传输数据，不能用于广播、寻址或路由。\nHTTP 传输的是文字、图片、音频、视频等超文本数据。\nHTTP 是构建互联网的重要基础技术，它没有实体，依赖许多其他的技术来实现，但同时许多技术也都依赖于它。\n\n把这些综合起来，使用递归缩写方式（模仿 PHP），我们可以把 HTTP 定义为“与 HTTP 协议相关的所有应用层技术的总和”。\n\n你可以对照这张图，看一下哪些部分是自己熟悉的，哪些部分是陌生的，又有哪些部分是想要进一步了解的，下一讲我会详细讲解这张图。\n课下作业\n\n有一种流行的说法：“HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议”，你认为这种说法对吗？对在哪里，又错在哪里？\n\n你能再说出几个“HTTP 不是什么”吗？\n\n欢迎你通过留言分享答案，与我和其他同学一起讨论。如果你觉得有所收获，欢迎你把文章分享给你的朋友。",
            "image": "https://www.banli17.com/imgs/2-2-1.jpeg",
            "date_modified": "2019-10-04T03:34:05.936Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-4.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-4.html",
            "title": "04 | HTTP 世界全览（下）：与 HTTP 相关的各种协议",
            "summary": "04 | HTTP 世界全览（下）：与 HTTP 相关的各种协议\n在上一讲中，我介绍了与 HTTP 相关的浏览器、服务器、CDN、网络爬虫等应用技术。\n今天要讲的则是比较偏向于理论的各种 HTTP 相关协议，重点是 TCP/IP、DNS、URI、HTTPS 等，希望能够帮你理清楚它们与 HTTP 的关系。\n同样的，我还是画了一张详细的思维导图，你可以点击后仔细查看。\n\nTCP/IP\nTCP/IP 协议是目前网络世界“事实上”的标准通信协议，即使你没有用过也一定听说过，因为它太著名了。\nTCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。\n这个协议栈有四层，最上层是“应用层”，最下层是“链接层”，TCP 和 IP 则在中间：TCP 属于“传输层”，IP 属于“网际层”。协议的层级关系模型非常重要，我会在下一讲中再专门讲解，这里先暂时放一放。\nIP 协议是“Internet Protocol”的缩写，主要目的是解决寻址和路由问题，以及如何在两点间传送数据包。IP 协议使用“IP 地址”的概念来定位互联网上的每一台计算机。可以对比一下现实中的电话系统，你拿着的手机相当于互联网上的计算机，而要打电话就必须接入电话网，由通信公司给你分配一个号码，这个号码就相当于 IP 地址。\n现在我们使用的 IP 协议大多数是 v4 版，地址是四个用“.”分隔的数字，例如“192.168.0.1”，总共有 2^32，大约 42 亿个可以分配的地址。看上去好像很多，但互联网的快速发展让地址的分配管理很快就“捉襟见肘”。所以，就又出现了 v6 版，使用 8 组“:”分隔的数字作为地址，容量扩大了很多，有 2^128 个，在未来的几十年里应该是足够用了。\nTCP 协议是“Transmission Control Protocol”的缩写，意思是“传输控制协议”，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。\n“可靠”是指保证数据不丢失，“字节流”是指保证数据完整，所以在 TCP 协议的两端可以如同操作文件一样访问传输的数据，就像是读写在一个密闭的管道里“流动”的字节。\n在第 2 讲时我曾经说过，HTTP 是一个&quot;传输协议&quot;，但它不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层来处理。因为互联网上最流行的是 TCP/IP 协议，而它刚好满足 HTTP 的要求，所以互联网上的 HTTP 协议就运行在了 TCP/IP 上，HTTP 也就可以更准确地称为“HTTP over TCP/IP”。\nDNS\n在 TCP/IP 协议中使用 IP 地址来标识计算机，数字形式的地址对于计算机来说是方便了，但对于人类来说却既难以记忆又难以输入。\n于是“域名系统”（Domain Name System）出现了，用有意义的名字来作为 IP 地址的等价替代。设想一下，你是愿意记“95.211.80.227”这样枯燥的数字，还是“nginx.org”这样的词组呢？\n在 DNS 中，“域名”（Domain Name）又称为“主机名”（Host），为了更好地标记不同国家或组织的主机，让名字更好记，所以被设计成了一个有层次的结构。\n域名用“.”分隔成多个单词，级别从左到右逐级升高，最右边的被称为“顶级域名”。对于顶级域名，可能你随口就能说出几个，例如表示商业公司的“com”、表示教育机构的“edu”，表示国家的“cn”“uk”等，买火车票时的域名还记得吗？是“www.12306.cn”。\n但想要使用 TCP/IP 协议来通信仍然要使用 IP 地址，所以需要把域名做一个转换，“映射”到它的真实 IP，这就是所谓的“域名解析”。\n继续用刚才的打电话做个比喻，你想要打电话给小明，但不知道电话号码，就得在手机里的号码簿里一项一项地找，直到找到小明那一条记录，然后才能查到号码。这里的“小明”就相当于域名，而“电话号码”就相当于 IP 地址，这个查找的过程就是域名解析。\n域名解析的实际操作要比刚才的例子复杂很多，因为互联网上的电脑实在是太多了。目前全世界有 13 组根 DNS 服务器，下面再有许多的顶级 DNS、权威 DNS 和更小的本地 DNS，逐层递归地实现域名查询。\nHTTP 协议中并没有明确要求必须使用 DNS，但实际上为了方便访问互联网上的 Web 服务器，通常都会使用 DNS 来定位或标记主机名，间接地把 DNS 与 HTTP 绑在了一起。\nURI/URL\n有了 TCP/IP 和 DNS，是不是我们就可以任意访问网络上的资源了呢？\n还不行，DNS 和 IP 地址只是标记了互联网上的主机，但主机上有那么多文本、图片、页面，到底要找哪一个呢？就像小明管理了一大堆文档，你怎么告诉他是哪个呢？\n所以就出现了 URI（Uniform Resource Identifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。\nURI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， 统一资源定位符，也就是我们俗称的“网址”，它实际上是 URI 的一个子集，不过因为这两者几乎是相同的，差异不大，所以通常不会做严格的区分。\n我就拿 Nginx 网站来举例，看一下 URI 是什么样子的。\nhttp://nginx.org/en/download.html\n\n你可以看到，URI 主要有三个基本的部分构成：\n协议名：即访问该资源应当使用的协议，在这里是“http”；\n主机名：即互联网上主机的标记，可以是域名或 IP 地址，在这里是“nginx.org”；\n路径：即资源在主机上的位置，使用“/”分隔多级目录，在这里是“/en/download.html”。\n还是用打电话来做比喻，你通过电话簿找到了小明，让他把昨天做好的宣传文案快递过来。那么这个过程中你就完成了一次 URI 资源访问，“小明”就是“主机名”，“昨天做好的宣传文案”就是“路径”，而“快递”，就是你要访问这个资源的“协议名”。\nHTTPS\n在 TCP/IP、DNS 和 URI 的“加持”之下，HTTP 协议终于可以自由地穿梭在互联网世界里，顺利地访问任意的网页了，真的是“好生快活”。\n但且慢，互联网上不仅有“美女”，还有很多的“野兽”。\n假设你打电话找小明要一份广告创意，很不幸，电话被商业间谍给窃听了，他立刻动用种种手段偷窃了你的快递，就在你还在等包裹的时候，他抢先发布了这份广告，给你的公司造成了无形或有形的损失。\n有没有什么办法能够防止这种情况的发生呢？确实有。你可以使用“加密”的方法，比如这样打电话：\n\n你：“喂，小明啊，接下来我们改用火星文通话吧。”\n小明：“好啊好啊，就用火星文吧。”\n你：“巴拉巴拉巴拉巴拉……”\n小明：“巴拉巴拉巴拉巴拉……”\n\n如果你和小明说的火星文只有你们两个才懂，那么即使窃听到了这段谈话，他也不会知道你们到底在说什么，也就无从破坏你们的通话过程。\nHTTPS 就相当于这个比喻中的“火星文”，它的全称是“HTTP over SSL/TLS”，也就是运行在 SSL/TLS 协议上的 HTTP。\n注意它的名字，这里是 SSL/TLS，而不是 TCP/IP，它是一个负责加密通信的安全协议，建立在 TCP/IP 之上，所以也是个可靠的传输协议，可以被用作 HTTP 的下层。\n因为 HTTPS 相当于“HTTP+SSL/TLS+TCP/IP”，其中的“HTTP”和“TCP/IP”我们都已经明白了，只要再了解一下 SSL/TLS，HTTPS 也就能够轻松掌握。\nSSL 的全称是“Secure Socket Layer”，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“Transport Layer Security”，但由于历史的原因还是有很多人称之为 SSL/TLS，或者直接简称为 SSL。\nSSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道，为 HTTP 套上一副坚固的盔甲。\n你可以在今后上网时留心看一下浏览器地址栏，如果有一个小锁头标志，那就表明网站启用了安全的 HTTPS 协议，而 URI 里的协议名，也从“http”变成了“https”。\n代理\n代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答。\n代理有很多的种类，常见的有：\n\n匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器；\n透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端；\n正向代理：靠近客户端，代表客户端向服务器发送请求；\n反向代理：靠近服务器端，代表服务器响应客户端的请求；\n\n上一讲提到的 CDN，实际上就是一种代理，它代替源站服务器响应客户端的请求，通常扮演着透明代理和反向代理的角色。\n由于代理在传输过程中插入了一个“中间层”，所以可以在这个环节做很多有意思的事情，比如：\n\n负载均衡：把访问请求均匀分散到多台机器，实现访问集群化；\n内容缓存：暂存上下行的数据，减轻后端的压力；\n安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器；\n数据处理：提供压缩、加密等额外的功能。\n\n关于 HTTP 的代理还有一个特殊的“代理协议”（proxy protocol），它由知名的代理软件 HAProxy 制订，但并不是 RFC 标准，我也会在之后的课程里专门讲解。\n小结\n这次我介绍了与 HTTP 相关的各种协议，在这里简单小结一下今天的内容。\n\nTCP/IP 是网络世界最常用的协议，HTTP 通常运行在 TCP/IP 提供的可靠传输基础上；\nDNS 域名是 IP 地址的等价替代，需要用域名解析实现到 IP 地址的映射；\nURI 是用来标记互联网上资源的一个名字，由“协议名 + 主机名 + 路径”构成，俗称 URL；\nHTTPS 相当于“HTTP+SSL/TLS+TCP/IP”，为 HTTP 套了一个安全的外壳；\n代理是 HTTP 传输过程中的“中转站”，可以实现缓存加速、负载均衡等功能。\n\n经过这两讲的学习，相信你应该对 HTTP 有了一个比较全面的了解，虽然还不是很深入，但已经为后续的学习扫清了障碍。\n课下作业\n\nDNS 与 URI 有什么关系？\n在讲代理时我特意没有举例说明，你能够用引入一个“小强”的角色，通过打电话来比喻一下吗？\n\n欢迎你通过留言分享答案，与我和其他同学一起讨论。如果你觉得有所收获，欢迎你把文章分享给你的朋友。\n\n每一次的 http 消息都是一个往返，请求先到服务器，然后服务器发回响应。正向代理是指“正”着代理客户端，反向代理是指“逆”着请求的方向代理服务器。\nuri 会有默认端口号，比如 http 默认是 80，用 tcp 连接必须要同时指定 ip 地址和端口。\n服务器进程在指定端口上监听，然后 tcp 就可以建立连接。\n字节流是一种抽象，是对比 udp 的包来说的，只有完整可靠的传输才能看成是字节流。",
            "image": "https://www.banli17.com/imgs/2-4-1.png",
            "date_modified": "2019-10-04T03:34:05.938Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-1.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-1.html",
            "title": "01 | 时势与英雄：HTTP 的前世今生",
            "summary": "01 | 时势与英雄：HTTP 的前世今生\nHTTP 协议在我们的生活中随处可见，打开手机或者电脑，只要你上网，不论是用 iPhone、Android、Windows 还是 Mac，不论是用浏览器还是 App，不论是看新闻、短视频还是听音乐、玩游戏，后面总会有 HTTP 在默默为你服务。\n据 NetCraft 公司统计，目前全球至少有 16 亿个网站、2 亿多个独立域名，而这个庞大网络世界的底层运转机制就是 HTTP。\n那么，在享受如此便捷舒适的网络生活时，你有没有想过，HTTP 协议是怎么来的？它最开始是什么样子的？又是如何一步一步发展到今天，几乎“统治”了整个互联网世界的呢？\n常言道：“时势造英雄，英雄亦造时势”。\n今天我就和你来聊一聊 HTTP 的发展历程，看看它的成长轨迹，看看历史上有哪些事件推动了它的前进，它又促进了哪些技术的产生，一起来见证“英雄之旅”。\n在这个过程中，你也能够顺便了解一下 HTTP 的“历史局限性”，明白 HTTP 为什么会设计成现在这个样子。\n史前时期\n20 世纪 60 年代，美国国防部高等研究计划署（ARPA）建立了 ARPA 网，它有四个分布在各地的节点，被认为是如今互联网的“始祖”。\n然后在 70 年代，基于对 ARPA 网的实践和思考，研究人员发明出了著名的 TCP/IP 协议。由于具有良好的分层结构和稳定的性能，TCP/IP 协议迅速战胜其他竞争对手流行起来，并在 80 年代中期进入了 UNIX 系统内核，促使更多的计算机接入了互联网。\n创世纪\n\n蒂姆·伯纳斯 - 李\n1989 年，任职于欧洲核子研究中心（CERN）的蒂姆·伯纳斯 - 李（Tim Berners-Lee）发表了一篇论文，提出了在互联网上构建超链接文档系统的构想。这篇论文中他确立了三项关键技术。\nURI：即统一资源标识符，作为互联网上资源的唯一身份；\nHTML：即超文本标记语言，描述超文本文档；\nHTTP：即超文本传输协议，用来传输超文本。\n这三项技术在如今的我们看来已经是稀松平常，但在当时却是了不得的大发明。基于它们，就可以把超文本系统完美地运行在互联网上，让各地的人们能够自由地共享信息，蒂姆把这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web。\n所以在这一年，我们的英雄“HTTP”诞生了，从此开始了它伟大的征途。\nHTTP/0.9\n20 世纪 90 年代初期的互联网世界非常简陋，计算机处理能力低，存储容量小，网速很慢，还是一片“信息荒漠”。网络上绝大多数的资源都是纯文本，很多通信协议也都使用纯文本，所以 HTTP 的设计也不可避免地受到了时代的限制。\n这一时期的 HTTP 被定义为 0.9 版，结构比较简单，为了便于服务器和客户端处理，它也采用了纯文本格式。蒂姆·伯纳斯 - 李最初设想的系统里的文档都是只读的，所以只允许用“GET”动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接，功能非常有限。\nHTTP/0.9 虽然很简单，但它作为一个“原型”，充分验证了 Web 服务的可行性，而“简单”也正是它的优点，蕴含了进化和扩展的可能性，因为：\n“把简单的系统变复杂”，要比“把复杂的系统变简单”容易得多。\nHTTP/1.0\n1993 年，NCSA（美国国家超级计算应用中心）开发出了 Mosaic，是第一个可以图文混排的浏览器，随后又在 1995 年开发出了服务器软件 Apache，简化了 HTTP 服务器的搭建工作。\n同一时期，计算机多媒体技术也有了新的发展：1992 年发明了 JPEG 图像格式，1995 年发明了 MP3 音乐格式。\n这些新软件新技术一经推出立刻就吸引了广大网民的热情，更的多的人开始使用互联网，研究 HTTP 并提出改进意见，甚至实验性地往协议里添加各种特性，从用户需求的角度促进了 HTTP 的发展。\n于是在这些已有实践的基础上，经过一系列的草案，HTTP/1.0 版本在 1996 年正式发布。它在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如：\n增加了 HEAD、POST 等新方法；\n增加了响应状态码，标记可能的错误原因；\n引入了协议版本号概念；\n引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活；\n传输的数据不再仅限于文本。\n但 HTTP/1.0 并不是一个“标准”，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个“备忘录”。\n所以 HTTP/1.0 的发布对于当时正在蓬勃发展的互联网来说并没有太大的实际意义，各方势力仍然按照自己的意图继续在市场上奋力拼杀。\nHTTP/1.1\n1995 年，网景的 Netscape Navigator 和微软的 Internet Explorer 开始了著名的“浏览器大战”，都希望在互联网上占据主导地位。\n这场战争的结果你一定早就知道了，最终微软的 IE 取得了决定性的胜利，而网景则“败走麦城”（但后来却凭借 Mozilla Firefox 又扳回一局）。\n“浏览器大战”的是非成败我们放在一边暂且不管，不可否认的是，它再一次极大地推动了 Web 的发展，HTTP/1.0 也在这个过程中经受了实践检验。于是在“浏览器大战”结束之后的 1999 年，HTTP/1.1 发布了 RFC 文档，编号为 2616，正式确立了延续十余年的传奇。\n从版本号我们就可以看到，HTTP/1.1 是对 HTTP/1.0 的小幅度修正。但一个重要的区别是：它是一个“正式的标准”，而不是一份可有可无的“参考文档”。这意味着今后互联网上所有的浏览器、服务器、网关、代理等等，只要用到 HTTP 协议，就必须严格遵守这个标准，相当于是互联网世界的一个“立法”。\n不过，说 HTTP/1.1 是“小幅度修正”也不太确切，它还是有很多实质性进步的。毕竟经过了多年的实战检验，比起 0.9/1.0 少了“学术气”，更加“接地气”，同时表述也更加严谨。HTTP/1.1 主要的变更点有：\n\n增加了 PUT、DELETE 等新的方法；\n增加了缓存管理和控制；\n明确了连接管理，允许持久连接；\n允许响应数据分块（chunked），利于传输大文件；\n强制要求 Host 头，让互联网主机托管成为可能。\n\nHTTP/1.1 的推出可谓是“众望所归”，互联网在它的“保驾护航”下迈开了大步，由此走上了“康庄大道”，开启了后续的“Web 1.0”“Web 2.0”时代。现在许多的知名网站都是在这个时间点左右创立的，例如 Google、新浪、搜狐、网易、腾讯等。\n不过由于 HTTP/1.1 太过庞大和复杂，所以在 2014 年又做了一次修订，原来的一个大文档被拆分成了六份较小的文档，编号为 7230-7235，优化了一些细节，但此外没有任何实质性的改动。\nHTTP/2\nHTTP/1.1 发布之后，整个互联网世界呈现出了爆发式的增长，度过了十多年的“快乐时光”，更涌现出了 Facebook、Twitter、淘宝、京东等互联网新贵。\n这期间也出现了一些对 HTTP 不满的意见，主要就是连接慢，无法跟上迅猛发展的互联网，但 HTTP/1.1 标准一直“岿然不动”，无奈之下人们只好发明各式各样的“小花招”来缓解这些问题，比如以前常见的切图、JS 合并等网页优化手段。\n终于有一天，搜索巨头 Google 忍不住了，决定“揭竿而起”，就像马云说的“如果银行不改变，我们就改变银行”。那么，它是怎么“造反”的呢？\nGoogle 首先开发了自己的浏览器 Chrome，然后推出了新的 SPDY 协议，并在 Chrome 里应用于自家的服务器，如同十多年前的网景与微软一样，从实际的用户方来“倒逼”HTTP 协议的变革，这也开启了第二次的“浏览器大战”。\n历史再次重演，不过这次的胜利者是 Google，Chrome 目前的全球的占有率超过了 60%。“挟用户以号令天下”，Google 借此顺势把 SPDY 推上了标准的宝座，互联网标准化组织以 SPDY 为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2，RFC 编号 7540。\nHTTP/2 的制定充分考虑了现今互联网的现状：宽带、移动、不安全，在高度兼容 HTTP/1.1 的同时在性能改善方面做了很大努力，主要的特点有：\n\n二进制协议，不再是纯文本；\n可发起多个请求，废弃了 1.1 里的管道；\n使用专用算法压缩头部，减少数据传输量；\n允许服务器主动向客户端推送数据；\n增强了安全性，“事实上”要求加密通信。\n虽然 HTTP/2 到今天已经四岁，也衍生出了 gRPC 等新协议，但由于 HTTP/1.1 实在是太过经典和强势，目前它的普及率还比较低，大多数网站使用的仍然还是 20 年前的 HTTP/1.1。\n\nHTTP/3\n看到这里，你可能会问了：“HTTP/2 这么好，是不是就已经完美了呢？”\n答案是否定的，这一次还是 Google，而且它要“革自己的命”。\n在 HTTP/2 还处于草案之时，Google 又发明了一个新的协议，叫做 QUIC，而且还是相同的“套路”，继续在 Chrome 和自家服务器里试验着“玩”，依托它的庞大用户量和数据量，持续地推动 QUIC 协议成为互联网上的“既成事实”。\n“功夫不负有心人”，当然也是因为 QUIC 确实自身素质过硬。\n在去年，也就是 2018 年，互联网标准化组织 IETF 提议将“HTTP over QUIC”更名为“HTTP/3”并获得批准，HTTP/3 正式进入了标准化制订阶段，也许两三年后就会正式发布，到时候我们很可能会跳过 HTTP/2 直接进入 HTTP/3。\n小结\n今天我和你一起跨越了三十年的历史长河，回顾了 HTTP 协议的整个发展过程，在这里简单小结一下今天的内容：\n\nHTTP 协议始于三十年前蒂姆·伯纳斯 - 李的一篇论文；\nHTTP/0.9 是个简单的文本协议，只能获取文本资源；\nHTTP/1.0 确立了大部分现在使用的技术，但它不是正式标准；\nHTTP/1.1 是目前互联网上使用最广泛的协议，功能也非常完善；\nHTTP/2 基于 Google 的 SPDY 协议，注重性能改善，但还未普及；\nHTTP/3 基于 Google 的 QUIC 协议，是将来的发展方向。\n\n希望通过今天的介绍，你能够对 HTTP 有一个初步但清晰的印象，知道了“来龙”才能更好地知道“去脉”。\n\n课下作业\n\n你认为推动 HTTP 发展的原动力是什么？\n你是怎么理解 HTTP（超文本传输协议）的？\n\n欢迎你把自己的答案写在留言区，与我和其他同学一起讨论。暂时回答不出来也不要紧，你可以带着这些问题在后续的课程里寻找答案。\n如果你觉得有所收获，欢迎你把文章分享给你的朋友。",
            "image": "https://www.banli17.com/imgs/2-1-1.jpeg",
            "date_modified": "2019-10-04T03:34:05.941Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-5.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-5.html",
            "title": "05 | 常说的“四层”和“七层”到底是什么？“五层”“六层”哪去了？",
            "summary": "05 | 常说的“四层”和“七层”到底是什么？“五层”“六层”哪去了？\n在上一讲中，我简单提到了 TCP/IP 协议，它是 HTTP 协议的下层协议，负责具体的数据传输工作。并且还特别说了，TCP/IP 协议是一个“有层次的协议栈”。\n在工作中你一定经常听别人谈起什么“四层负载均衡”“七层负载均衡”，什么“二层转发”“三层路由”，那么你真正理解这些层次的含义吗？\n网络分层的知识教科书上都有，但很多都是“泛泛而谈”，只有“学术价值”，于是就容易和实际应用“脱节”，造成的后果就是“似懂非懂”，真正用的时候往往会“一头雾水”。\n所以，今天我就从 HTTP 应用的角度，帮你把这些模糊的概念弄清楚。\nTCP/IP 网络分层模型\n还是先从 TCP/IP 协议开始讲起，一是因为它非常经典，二是因为它是目前事实上的网络通信标准，研究它的实用价值最大。\nTCP/IP 当初的设计者真的是非常聪明，创造性地提出了“分层”的概念，把复杂的网络通信划分出多个层次，再给每一个层次分配不同的职责，层次内只专心做自己的事情就好，用“分而治之”的思想把一个“大麻烦”拆分成了数个“小麻烦”，从而解决了网络通信的难题。\n你应该对 TCP/IP 的协议栈有所了解吧，这里我再贴一下层次图。\n\nTCP/IP 协议总共有四层，就像搭积木一样，每一层需要下层的支撑，同时又支撑着上层，任何一层被抽掉都可能会导致整个协议栈坍塌。\n我们来仔细地看一下这个精巧的积木架构，注意它的层次顺序是“从下往上”数的，所以第一层就是最下面的一层。\n第一层叫“链接层”（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层。\n第二层叫“网际层”或者“网络互连层”（internet layer），IP 协议就处在这一层。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。\n第三层叫“传输层”（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP。\nTCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的“字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。\n关于 TCP 和 UDP 可以展开讨论的话题还有很多，比如最经典的“三次握手”和“四次挥手”，一时半会很难说完，好在与 HTTP 的关系不是太大，以后遇到了再详细讲解。\n协议栈的第四层叫“应用层”（application layer），由于下面的三层把基础打得非常好，所以在这一层就“百花齐放”了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 HTTP。\nMAC 层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\nOSI 网络分层模型\n看完 TCP/IP 协议栈，你可能要问了，“它只有四层，那常说的七层怎么没见到呢？”\n别着急，这就是今天要说的第二个网络分层模型：OSI，全称是“开放式系统互联通信参考模型”（Open System Interconnection Reference Model）。\nTCP/IP 发明于 1970 年代，当时除了它还有很多其他的网络协议，整个网络世界比较混乱。\n这个时候国际标准组织（ISO）注意到了这种现象，感觉“野路子”太多，就想要来个“大一统”。于是设计出了一个新的网络分层模型，想用这个新框架来统一既存的各种网络协议。\nOSI 模型分成了七层，部分层次与 TCP/IP 很像，从下到上分别是：\n\n第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等；\n第二层：数据链路层，它基本相当于 TCP/IP 的链接层；\n第三层：网络层，相当于 TCP/IP 里的网际层；\n第四层：传输层，相当于 TCP/IP 里的传输层；\n第五层：会话层，维护网络中的连接状态，即保持会话和同步；\n第六层：表示层，把数据转换为合适、可理解的语法和语义；\n第七层：应用层，面向具体的应用传输数据。\n\n至此，我们常说的“四层”“七层”就出现了。\n不过国际标准组织心里也很清楚，TCP/IP 等协议已经在许多网络上实际运行，再推翻重来是不可能的。所以，OSI 分层模型在发布的时候就明确地表明是一个“参考”，不是强制标准，意思就是说，“你们以后该干什么还干什么，我不管，但面子上还是要按照我说的来”。\n但 OSI 模型也是有优点的。对比一下就可以看出，TCP/IP 是一个纯软件的栈，没有网络应有的最根基的电缆、网卡等物理设备的位置。而 OSI 则补足了这个缺失，在理论层面上描述网络更加完整。\n还有一个重要的形式上的优点：OSI 为每一层标记了明确了编号，最底层是一层，最上层是七层，而 TCP/IP 的层次从来只有名字而没有编号。显然，在交流的时候说“七层”要比“应用层”更简单快捷，特别是英文，对比一下“Layer seven”与“application layer”。\n综合以上几点，在 OSI 模型之后，“四层”“七层”这样的说法就逐渐流行开了。不过在实际工作中你一定要注意，这种说法只是“理论上”的层次，并不是与现实完全对应。\n两个分层模型的映射关系\n现在我们有了两个网络分层模型：TCP/IP 和 OSI，新的问题又出现了，一个是四层模型，一个是七层模型，这两者应该如何互相映射或者说互相解释呢？\n好在 OSI 在设计之初就参考了 TCP/IP 等多个协议，可以比较容易但不是很精确地实现对应关系。\n\n第一层：物理层，TCP/IP 里无对应；\n第二层：数据链路层，对应 TCP/IP 的链接层；\n第三层：网络层，对应 TCP/IP 的网际层；\n第四层：传输层，对应 TCP/IP 的传输层；\n第五、六、七层：统一对应到 TCP/IP 的应用层。\n\n所以你看，这就是“理想与现实”之间的矛盾。理想很美好，有七层，但现实很残酷，只有四层，“多余”的五层、六层就这样“消失”了。\n但这也有一定的实际原因。\nOSI 的分层模型在四层以上分的太细，而 TCP/IP 实际应用时的会话管理、编码转换、压缩等和具体应用经常联系的很紧密，很难分开。例如，HTTP 协议就同时包含了连接管理和数据格式定义。\n到这里，你应该能够明白一开始那些“某某层”的概念了。\n所谓的“四层负载均衡”就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。\n所谓的“七层负载均衡”就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。\nTCP/IP 协议栈的工作方式\nTCP/IP 协议栈是如何工作的呢？\n你可以把 HTTP 利用 TCP/IP 协议栈传输数据想象成一个发快递的过程。\n假设你想把一件毛绒玩具送给朋友，但你要先拿个塑料袋套一下，这件玩具就相当于 HTTP 协议里要传输的内容，比如 HTML，然后 HTTP 协议为它加一个 HTTP 专用附加数据。\n你把玩具交给快递小哥，为了保护货物，他又加了层包装再贴了个标签，相当于在 TCP 层给数据再次打包，加上了 TCP 头。\n接着快递小哥下楼，把包裹放进了三轮车里，运到集散点，然后再装进更大的卡车里，相当于在 IP 层、MAC 层对 TCP 数据包加上了 IP 头、MAC 头。\n之后经过漫长的运输，包裹到达目的地，要卸货再放进另一位快递员的三轮车，就是在 IP 层、MAC 层传输后拆包。\n快递员到了你朋友的家门口，撕掉标签，去除了 TCP 层的头，你朋友再拆掉塑料袋包装，也就是 HTTP 头，最后就拿到了玩具，也就是真正的 HTML 页面。\n这个比喻里省略了很多 TCP/IP 协议里的细节，比如建连、路由、数据切分与重组、错误检查等，但核心的数据传输过程是差不多的。\nHTTP 协议的传输过程就是这样通过协议栈逐层向下，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去。\n接收数据是则是相反的操作，从下往上穿过协议栈，逐层拆包，每层去掉本层的专有头，上层就会拿到自己的数据。\n但下层的传输过程对于上层是完全“透明”的，上层也不需要关心下层的具体实现细节，所以就 HTTP 层次来看，它不管下层是不是 TCP/IP 协议，看到的只是一个可靠的传输链路，只要把数据加上自己的头，对方就能原样收到。\n我为这个过程画了一张图，你可以对照着加深理解。\n\n小结\n这次我们学习了 HTTP 所在的网络分层模型，它是工作中常用的交流语言，在这里简单小结一下今天的内容。\n\nTCP/IP 分为四层，核心是二层的 IP 和三层的 TCP，HTTP 在第四层；\nOSI 分为七层，基本对应 TCP/IP，TCP 在第四层，HTTP 在第七层；\nOSI 可以映射到 TCP/IP，但这期间一、五、六层消失了；\n日常交流的时候我们通常使用 OSI 模型，用四层、七层等术语；\nHTTP 利用 TCP/IP 协议栈逐层打包再拆包，实现了数据传输，但下面的细节并不可见。\n\n有一个辨别四层和七层比较好的（但不是绝对的）小窍门，“两个凡是”：凡是由操作系统负责处理的就是四层或四层以下，否则，凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层。\n课下作业\n\n你能用自己的话解释一下“二层转发”“三层路由”吗？\n你认为上一讲中的 DNS 协议位于哪一层呢？\n你认为 CDN 工作在那一层呢？\n\n欢迎你把自己的答案写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。\n\n二层转发：设备工作在链接层，获取了数据报的头部信息之后，根据目标的 MAC 地址，进行本地转发和广播\n三层路由：设备工作在 IP 层，通过分析数据报的头部信息，得到 IP 地址，根据网段范围，进行本地转发或选择下一个网关\ndns 和 cdn 都在应用层",
            "image": "https://www.banli17.com/imgs/2-5-1.png",
            "date_modified": "2019-10-04T03:34:05.943Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-6.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-6.html",
            "title": "06 | 域名里有哪些门道？",
            "summary": "06 | 域名里有哪些门道？\n在上一讲里，我们学习了 HTTP 协议使用的 TCP/IP 协议栈，知道了 HTTP 协议是运行在 TCP/IP 上的。\nIP 协议的职责是“网际互连”，它在 MAC 层之上，使用 IP 地址把 MAC 编号转换成了四位数字，这就对物理网卡的 MAC 地址做了一层抽象，发展出了许多的“新玩法”。\n例如，分为 A、B、C、D、E 五种类型，公有地址和私有地址，掩码分割子网等。只要每个小网络在 IP 地址这个概念上达成一致，不管它在 MAC 层有多大的差异，都可以接入 TCP/IP 协议栈，最终汇合进整个互联网。\n但接入互联网的计算机越来越多，IP 地址的缺点也就暴露出来了，最主要的是它“对人不友好”，虽然比 MAC 的 16 进制数要好一点，但还是难于记忆和输入。\n怎么解决这个问题呢？\n那就“以其人之道还治其人之身”，在 IP 地址之上再来一次抽象，把数字形式的 IP 地址转换成更有意义更好记的名字，在字符串的层面上再增加“新玩法”。于是，DNS 域名系统就这么出现了。\n域名的形式\n在第 4 讲曾经说过，域名是一个有层次的结构，是一串用“.”分隔的多个单词，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低。\n最左边的是主机名，通常用来表明主机的用途，比如“www”表示提供万维网服务、“mail”表示提供邮件服务，不过这也不是绝对的，名字的关键是要让我们容易记忆。\n看一下极客时间的域名“time.geekbang.org”，这里的“org”就是顶级域名，“geekbang”是二级域名，“time”则是主机名。使用这个域名，DNS 就会把它转换成相应的 IP 地址，你就可以访问极客时间的网站了。\n域名不仅能够代替 IP 地址，还有许多其他的用途。\n在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务，比如在 Nginx 里就会使用“server_name”指令：\nserver {\n    listen 80;                       # 监听 80 端口\n    server_name  time.geekbang.org;  # 主机名是 time.geekbang.org\n    ...\n}\n\n域名本质上还是个名字空间系统，使用多级域名就可以划分出不同的国家、地区、组织、公司、部门，每个域名都是独一无二的，可以作为一种身份的标识。\n举个例子吧，假设 A 公司里有个小明，B 公司里有个小强，于是他们就可以分别说是“小明.A 公司”，“小强.B 公司”，即使 B 公司里也有个小明也不怕，可以标记为“小明.B 公司”，很好地解决了重名问题。\n因为这个特性，域名也被扩展到了其他应用领域，比如 Java 的包机制就采用域名作为命名空间，只是它使用了反序。如果极客时间要开发 Java 应用，那么它的包名可能就是“org.geekbang.time”。\n而 XML 里使用 URI 作为名字空间，也是间接使用了域名。\n域名的解析\n就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是“域名解析”。\n目前全世界有几亿个站点，有几十亿网民，而每天网络上发生的 HTTP 流量更是天文数字。这些请求绝大多数都是基于域名来访问网站的，所以 DNS 就成了互联网的重要基础设施，必须要保证域名解析稳定可靠、快速高效。\nDNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：\n\n根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址；\n顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；\n权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址。\n\n在这里根域名服务器是关键，它必须是众所周知的，否则下面的各级服务器就无从谈起了。目前全世界共有 13 组根域名服务器，又有数百台的镜像，保证一定能够被访问到。\n有了这个系统以后，任何一个域名都可以在这个树形结构里从顶至下进行查询，就好像是把域名从右到左顺序走了一遍，最终就获得了域名对应的 IP 地址。\n例如，你要访问“www.apple.com”，就要进行下面的三次查询：\n\n访问根域名服务器，它会告诉你“com”顶级域名服务器的地址；\n访问“com”顶级域名服务器，它再告诉你“apple.com”域名服务器的地址；\n最后访问“apple.com”域名服务器，就得到了“www.apple.com”的地址。\n\n虽然核心的 DNS 系统遍布全球，服务能力很强也很稳定，但如果全世界的网民都往这个系统里挤，即使不挤瘫痪了，访问速度也会很慢。\n所以在核心 DNS 系统之外，还有两种手段用来减轻域名解析的压力，并且能够更快地获取结果，基本思路就是“缓存”。\n首先，许多大公司、网络运行商都会建立自己的 DNS 服务器，作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。这些“野生”服务器被称为“非权威域名服务器”，可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址。\n这些 DNS 服务器的数量要比核心系统的服务器多很多，而且大多部署在离用户很近的地方。比较知名的 DNS 有 Google 的“8.8.8.8”，Microsoft 的“4.2.2.1”，还有 CloudFlare 的“1.1.1.1”等等。\n其次，操作系统里也会对 DNS 解析结果做缓存，如果你之前访问过“www.apple.com”，那么下一次在浏览器里再输入这个网址的时候就不会再跑到 DNS 那里去问了，直接在操作系统里就可以拿到 IP 地址。\n另外，操作系统里还有一个特殊的“主机映射”文件，通常是一个可编辑的文本，在 Linux 里是“/etc/hosts”，在 Windows 里是“C:\\WINDOWS\\system32\\drivers\\etc\\hosts”，如果操作系统在缓存里找不到 DNS 记录，就会找这个文件。\n有了上面的“野生”DNS 服务器、操作系统缓存和 hosts 文件后，很多域名解析的工作就都不用“跋山涉水”了，直接在本地或本机就能解决，不仅方便了用户，也减轻了各级 DNS 服务器的压力，效率就大大提升了。\n下面的这张图比较完整地表示了现在的 DNS 架构。\n\n在 Nginx 里有这么一条配置指令“resolver”，它就是用来配置 DNS 服务器的，如果没有它，那么 Nginx 就无法查询域名对应的 IP，也就无法反向代理到外部的网站。\nresolver 8.8.8.8 valid=30s;  # 指定 Google 的 DNS，缓存 30 秒\n\n域名的“新玩法”\n有了域名，又有了可以稳定工作的解析系统，于是我们就可以实现比 IP 地址更多的“新玩法”了。\n第一种，也是最简单的，“重定向”。因为域名代替了 IP 地址，所以可以让对外服务的域名不变，而主机的 IP 地址任意变动。当主机有情况需要下线、迁移时，可以更改 DNS 记录，让域名指向其他的机器。\n比如，你有一台“buy.tv”的服务器要临时停机维护，那你就可以通知 DNS 服务器：“我这个 buy.tv 域名的地址变了啊，原先是 1.2.3.4，现在是 5.6.7.8，麻烦你改一下。”DNS 于是就修改内部的 IP 地址映射关系，之后再有访问 buy.tv 的请求就不走 1.2.3.4 这台主机，改由 5.6.7.8 来处理，这样就可以保证业务服务不中断。\n第二种，因为域名是一个名字空间，所以可以使用 bind9 等开源软件搭建一个在内部使用的 DNS，作为名字服务器。这样我们开发的各种内部服务就都用域名来标记，比如数据库服务都用域名“mysql.inner.app”，商品服务都用“goods.inner.app”，发起网络通信时也就不必再使用写死的 IP 地址了，可以直接用域名，而且这种方式也兼具了第一种“玩法”的优势。\n第三种“玩法”包含了前两种，也就是基于域名实现的负载均衡。\n这种“玩法”也有两种方式，两种方式可以混用。\n第一种方式，因为域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机，客户端收到多个 IP 地址后，就可以自己使用轮询算法依次向服务器发起请求，实现负载均衡。\n第二种方式，域名解析可以配置内部的策略，返回离客户端最近的主机，或者返回当前服务质量最好的主机，这样在 DNS 端把请求分发到不同的服务器，实现负载均衡。\n前面我们说的都是可信的 DNS，如果有一些不怀好意的 DNS，那么它也可以在域名这方面“做手脚”，弄一些比较“恶意”的“玩法”，举两个例子：\n\n“域名屏蔽”，对域名直接不解析，返回错误，让你无法拿到 IP 地址，也就无法访问网站；\n“域名劫持”，也叫“域名污染”，你要访问 A 网站，但 DNS 给了你 B 网站。\n\n好在互联网上还是好人多，而且 DNS 又是互联网的基础设施，这些“恶意 DNS”并不多见，你上网的时候不需要太过担心。\n小结\n这次我们学习了与 HTTP 协议有重要关系的域名和 DNS，在这里简单小结一下今天的内容：\n\n域名使用字符串来代替 IP 地址，方便用户记忆，本质上一个名字空间系统；\nDNS 就像是我们现实世界里的电话本、查号台，统管着互联网世界里的所有网站，是一个“超级大管家”；\nDNS 是一个树状的分布式查询系统，但为了提高查询效率，外围有多级的缓存；\n使用 DNS 可以实现基于域名的负载均衡，既可以在内网，也可以在外网。\n\n课下作业\n\n在浏览器地址栏里随便输入一个不存在的域名，比如就叫“www. 不存在.com”，试着解释一下它的 DNS 解析过程。\n如果因为某些原因，DNS 失效或者出错了，会出现什么后果？\n\n欢迎你把自己的答案写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。\n\n为何全世界只有 13 组根域名服务器呢？\n细节原因不好解释，简单来说是因为 dns 协议还有 udp 协议里包大小的限制，只有 512 字节，再除以 dns 记录长度，最多 15 组，再去掉 buffer。\n域名由专门的域名注册机构管理，终极的是 ICANN。\nIP 地址的分配也由 ICANN 管理，当然有浪费，美国是互联网的发明国，所以占用 ip 地址最多。\nip 地址查找由专门的协议，比如 arp。",
            "image": "https://www.banli17.com/imgs/2-6-1.png",
            "date_modified": "2019-10-04T03:34:05.945Z"
        },
        {
            "id": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-7.html",
            "url": "https://www.banli17.com/reads/%E9%80%8F%E8%A7%86http%E5%8D%8F%E8%AE%AE/2-7.html",
            "title": "07 | 自己动手，搭建 HTTP 实验环境",
            "summary": "07 | 自己动手，搭建 HTTP 实验环境\n这一讲是“破冰篇”的最后一讲，我会先简单地回顾一下之前的内容，然后在 Windows 系统上实际操作，用几个应用软件搭建出一个“最小化”的 HTTP 实验环境，方便后续的“基础篇”“进阶篇”“安全篇”的学习。\n“破冰篇”回顾\nHTTP 协议诞生于 30 年前，设计之初的目的是用来传输纯文本数据。但由于形式灵活，搭配 URI、HTML 等技术能够把互联网上的资源都联系起来，构成一个复杂的超文本系统，让人们自由地获取信息，所以得到了迅猛发展。\nHTTP 有多个版本，目前应用的最广泛的是 HTTP/1.1，它几乎可以说是整个互联网的基石。但 HTTP/1.1 的性能难以满足如今的高流量网站，于是又出现了 HTTP/2 和 HTTP/3。不过这两个新版本的协议还没有完全推广开。在可预见的将来，HTTP/1.1 还会继续存在下去。\nHTTP 翻译成中文是“超文本传输协议”，是一个应用层的协议，通常基于 TCP/IP，能够在网络的任意两点之间传输文字、图片、音频、视频等数据。\nHTTP 协议中的两个端点称为请求方和应答方。请求方通常就是 Web 浏览器，也叫 user agent，应答方是 Web 服务器，存储着网络上的大部分静态或动态的资源。\n在浏览器和服务器之间还有一些“中间人”的角色，如 CDN、网关、代理等，它们也同样遵守 HTTP 协议，可以帮助用户更快速、更安全地获取资源。\nHTTP 协议不是一个孤立的协议，需要下层很多其他协议的配合。最基本的是 TCP/IP，实现寻址、路由和可靠的数据传输，还有 DNS 协议实现对互联网上主机的定位查找。\n对 HTTP 更准确的称呼是“HTTP over TCP/IP”，而另一个“HTTP over SSL/TLS”就是增加了安全功能的 HTTPS。\n软件介绍\n常言道“实践出真知”，又有俗语“光说不练是假把式”。要研究 HTTP 协议，最好有一个实际可操作、可验证的环境，通过实际的数据、现象来学习，肯定要比单纯的“动嘴皮子”效果要好的多。\n现成的环境当然有，只要能用浏览器上网，就会有 HTTP 协议，就可以进行实验。但现实的网络环境又太复杂了，有很多无关的干扰因素，这些“噪音”会“淹没”真正有用的信息。\n所以，我给你的建议是：搭建一个“最小化”的环境，在这个环境里仅有 HTTP 协议的两个端点：请求方和应答方，去除一切多余的环节，从而可以抓住重点，快速掌握 HTTP 的本质。\n\n简单说一下这个“最小化”环境用到的应用软件：\n\nWireshark\nChrome/Firefox\nTelnet\nOpenResty\n\nWireshark 是著名的网络抓包工具，能够截获在 TCP/IP 协议栈中传输的所有流量，并按协议类型、地址、端口等任意过滤，功能非常强大，是学习网络协议的必备工具。\n它就像是网络世界里的一台“高速摄像机”，把只在一瞬间发生的网络传输过程如实地“拍摄”下来，事后再“慢速回放”，让我们能够静下心来仔细地分析那一瞬到底发生了什么。\nChrome 是 Google 开发的浏览器，是目前的主流浏览器之一。它不仅上网方便，也是一个很好的调试器，对 HTTP/1.1、HTTPS、HTTP/2、QUIC 等的协议都支持得非常好，用 F12 打开“开发者工具”还可以非常详细地观测 HTTP 传输全过程的各种数据。\n如果你更习惯使用 Firefox，那也没问题，其实它和 Chrome 功能上都差不太多，选择自己喜欢的就好。\n与 Wireshark 不同，Chrome 和 Firefox 属于“事后诸葛亮”，不能观测 HTTP 传输的过程，只能看到结果。\nTelnet 是一个经典的虚拟终端，基于 TCP 协议远程登录主机，我们可以使用它来模拟浏览器的行为，连接服务器后手动发送 HTTP 请求，把浏览器的干扰也彻底排除，能够从最原始的层面去研究 HTTP 协议。\nOpenResty 你可能比较陌生，它是基于 Nginx 的一个“强化包”，里面除了 Nginx 还有一大堆有用的功能模块，不仅支持 HTTP/HTTPS，还特别集成了脚本语言 Lua 简化 Nginx 二次开发，方便快速地搭建动态网关，更能够当成应用容器来编写业务逻辑。\n选择 OpenResty 而不直接用 Nginx 的原因是它相当于 Nginx 的“超集”，功能更丰富，安装部署更方便。我也会用 Lua 编写一些服务端脚本，实现简单的 Web 服务器响应逻辑，方便实验。\n安装过程\n这个“最小化”环境的安装过程也比较简单，大约只需要你半个小时不到的时间就能搭建完成。\n我在 GitHub 上为本专栏开了一个项目：http_study，可以直接用“git clone”下载，或者去 Release 页面，下载打好的压缩包。\n我使用的操作环境是 Windows 10，如果你用的是 Mac 或者 Linux，可以用 VirtualBox 等虚拟机软件安装一个 Windows 虚拟机，再在里面操作。\n首先你要获取最新的 httpstudy 项目源码，假设 clone 或解压的目录是“D:\\httpstudy”，操作完成后大概是下图这个样子。\n\nChrome 和 WireShark 的安装比较简单，一路按“下一步”就可以了。版本方面使用最新的就好，我的版本可能不是最新的，Chrome 是 73，WireShark 是 3.0.0。\nWindows 10 自带 Telnet，不需要安装，但默认是不启用的，需要你稍微设置一下。\n打开 Windows 的设置窗口，搜索“Telnet”，就会找到“启用或关闭 Windows 功能”，在这个窗口里找到“Telnet 客户端”，打上对钩就可以了，可以参考截图。\n\n接下来我们要安装 OpenResty，去它的官网，点击左边栏的“Download”，进入下载页面，下载适合你系统的版本（这里我下载的是 64 位的 1.15.8.1，包的名字是“openresty-1.15.8.1-win64.zip”）。\n\n然后要注意，你必须把 OpenResty 的压缩包解压到刚才的“D:\\http_study”目录里，并改名为“openresty”。\n\n安装工作马上就要完成了，为了能够让浏览器能够使用 DNS 域名访问我们的实验环境，还要改一下本机的 hosts 文件，位置在“C:\\WINDOWS\\system32\\drivers\\etc”，在里面添加三行本机 IP 地址到测试域名的映射，你也可以参考 GitHub 项目里的 hosts 文件，这就相当于在一台物理实机上“托管”了三个虚拟主机。\n127.0.0.1       www.chrono.com\n127.0.0.1       www.metroid.net\n127.0.0.1       origin.io\n\n注意修改 hosts 文件需要管理员权限，直接用记事本编辑是不行的，可以切换管理员身份，或者改用其他高级编辑器，比如 Notepad++，而且改之前最好做个备份。\n到这里，我们的安装工作就完成了！之后你就可以用 Wireshark、Chrome、Telnet 在这个环境里随意“折腾”，弄坏了也不要紧，只要把目录删除，再来一遍操作就能复原。\n测试验证\n实验环境搭建完了，但还需要把它运行起来，做一个简单的测试验证，看是否运转正常。\n首先我们要启动 Web 服务器，也就是 OpenResty。\n在 http_study 的“www”目录下有四个批处理文件，分别是：\n\nstart：启动 OpenResty 服务器；\nstop：停止 OpenResty 服务器；\nreload：重启 OpenResty 服务器；\nlist：列出已经启动的 OpenResty 服务器进程。\n\n使用鼠标双击“start”批处理文件，就会启动 OpenResty 服务器在后台运行，这个过程可能会有 Windows 防火墙的警告，选择“允许”即可。\n运行后，鼠标双击“list”可以查看 OpenResty 是否已经正常启动，应该会有两个 nginx.exe 的后台进程，大概是下图的样子。\n\n有了 Web 服务器后，接下来我们要运行 Wireshark，开始抓包。\n因为我们的实验环境运行在本机的 127.0.0.1 上，也就是 loopback“环回”地址。所以，在 Wireshark 里要选择“Npcap loopback Adapter”，过滤器选择“HTTP TCP port(80)”，即只抓取 HTTP 相关的数据包。鼠标双击开始界面里的“Npcap loopback Adapter”即可开始抓取本机上的网络数据。\n\n然后我们打开 Chrome，在地址栏输入“http://localhost/”，访问刚才启动的 OpenResty 服务器，就会看到一个简单的欢迎界面，如下图所示。\n\n这时再回头去看 Wireshark，应该会显示已经抓到了一些数据，就可以用鼠标点击工具栏里的“停止捕获”按钮告诉 Wireshark“到此为止”，不再继续抓包。\n\n至于这些数据是什么，表示什么含义，我会在下一讲再详细介绍。\n如果你能够在自己的电脑上走到这一步，就说明“最小化”的实验环境已经搭建成功了，不要忘了实验结束后运行批处理“stop”停止 OpenResty 服务器。\n小结\n这次我们学习了如何在自己的电脑上搭建 HTTP 实验环境，在这里简单小结一下今天的内容。\n\n现实的网络环境太复杂，有很多干扰因素，搭建“最小化”的环境可以快速抓住重点，掌握 HTTP 的本质；\n我们选择 Wireshark 作为抓包工具，捕获在 TCP/IP 协议栈中传输的所有流量；\n我们选择 Chrome 或 Firefox 浏览器作为 HTTP 协议中的 user agent；\n我们选择 OpenResty 作为 Web 服务器，它是一个 Nginx 的“强化包”，功能非常丰富；\nTelnet 是一个命令行工具，可用来登录主机模拟浏览器操作；\n\n在 GitHub 上可以下载到本专栏的专用项目源码，只要把 OpenResty 解压到里面即可完成实验环境的搭建。\n课下作业\n\n按照今天所学的，在你自己的电脑上搭建出这个 HTTP 实验环境并测试验证。\n\n由于篇幅所限，我无法详细介绍 Wireshark，你有时间可以再上网搜索 Wireshark 相关的资料，了解更多的用法。\n\n欢迎你把自己的学习体会写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。\n",
            "image": "https://www.banli17.com/imgs/2-7-1.png",
            "date_modified": "2019-10-04T03:34:05.948Z"
        }
    ]
}